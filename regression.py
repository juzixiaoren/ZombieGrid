import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from skopt import gp_minimize
from skopt.space import Real, Integer
from generate_data import load_market_from_db
import warnings
warnings.filterwarnings('ignore')

# -----------------------------
# 1. é…ç½®ï¼šåªéœ€ä¿®æ”¹è¿™ä¸€è¡Œ
# -----------------------------
TARGET_COLUMN = 'ç­–ç•¥ XIRR'  # â†â†â† åœ¨è¿™é‡ŒæŒ‡å®šä½ çš„ç›®æ ‡è¾“å‡ºåˆ—ï¼ˆå¿…é¡»æ˜¯ä¸‹é¢5ä¸ªä¹‹ä¸€ï¼‰

# -----------------------------
# 2. æ ¹æ®ä½ çš„è¡¨æ ¼åˆ—åç²¾ç¡®åˆ¤æ–­ä¼˜åŒ–æ–¹å‘
# -----------------------------
if TARGET_COLUMN in ['ç­–ç•¥ XIRR', 'å¹´åŒ–å¤æ™®æ¯”']:
    OPTIMIZE_MODE = 'maximize'
elif TARGET_COLUMN in ['æœ€å¤§å›æ’¤ (ç›¸å¯¹å³°å€¼)', 'æœ€å¤§å›æ’¤ (ç›¸å¯¹åˆå§‹)', 'å¹´åŒ–æ³¢åŠ¨ç‡']:
    OPTIMIZE_MODE = 'minimize'
else:
    raise ValueError(
        f"âŒ ä¸æ”¯æŒçš„ç›®æ ‡åˆ—: '{TARGET_COLUMN}'\n"
        "âœ… è¯·ä½¿ç”¨ä»¥ä¸‹åˆ—åä¹‹ä¸€:\n"
        "   - æœ€å¤§åŒ–: 'ç­–ç•¥ XIRR', 'å¹´åŒ–å¤æ™®æ¯”'\n"
        "   - æœ€å°åŒ–: 'æœ€å¤§å›æ’¤ (ç›¸å¯¹å³°å€¼)', 'æœ€å¤§å›æ’¤ (ç›¸å¯¹åˆå§‹)', 'å¹´åŒ–æ³¢åŠ¨ç‡'"
    )

# -----------------------------
# 3. åŠ è½½ä½ çš„ Excel æ•°æ®ï¼ˆæ–‡ä»¶åå¿…é¡»ä¸º OutPut.xlsxï¼‰
# -----------------------------
try:
    df = pd.read_excel('OutPut.xlsx', engine='openpyxl')
    print(f"âœ… æˆåŠŸåŠ è½½ 'OutPut.xlsx'ï¼Œå…± {len(df)} è¡Œæ•°æ®")
except FileNotFoundError:
    raise FileNotFoundError("âŒ æ‰¾ä¸åˆ° 'OutPut.xlsx'ï¼Œè¯·ç¡®ä¿è¯¥æ–‡ä»¶åœ¨å½“å‰ç›®å½•")
except Exception as e:
    raise RuntimeError(f"âŒ è¯»å– Excel æ–‡ä»¶å¤±è´¥: {e}")

# æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
required_inputs = ['a', 'b', 'é¦–è¡Œä¹°å…¥è§¦å‘ä»·', 'æ¨¡å‹è¡Œæ•°', 'ä¹°å…¥é‡‘é¢']
required_outputs = ['ç­–ç•¥ XIRR', 'æœ€å¤§å›æ’¤ (ç›¸å¯¹å³°å€¼)', 'æœ€å¤§å›æ’¤ (ç›¸å¯¹åˆå§‹)', 'å¹´åŒ–å¤æ™®æ¯”', 'å¹´åŒ–æ³¢åŠ¨ç‡']

missing_inputs = [col for col in required_inputs if col not in df.columns]
missing_outputs = [col for col in required_outputs if col not in df.columns]

if missing_inputs:
    raise ValueError(f"âŒ è¾“å…¥åˆ—ç¼ºå¤±: {missing_inputs}")
if TARGET_COLUMN not in df.columns:
    raise ValueError(f"âŒ ç›®æ ‡åˆ— '{TARGET_COLUMN}' ä¸åœ¨æ•°æ®ä¸­ã€‚å¯ç”¨åˆ—: {required_outputs}")

# å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
X = df[required_inputs]
y = df[TARGET_COLUMN]

# åˆ é™¤ç›®æ ‡åˆ—ä¸­çš„ NaN è¡Œ
initial_count = len(y)
valid_mask = y.notna()
X = X[valid_mask]
y = y[valid_mask]
final_count = len(y)

print(f"ğŸ“Š æ•°æ®è¿‡æ»¤: {initial_count} â†’ {final_count} è¡Œ (ç§»é™¤ {initial_count - final_count} è¡Œ NaN)")

# -----------------------------
# 4. è®­ç»ƒå›å½’æ¨¡å‹
# -----------------------------
print(f"ğŸ¯ ç›®æ ‡: '{TARGET_COLUMN}' â†’ ä¼˜åŒ–æ–¹å‘: {OPTIMIZE_MODE}")
print("â³ æ­£åœ¨è®­ç»ƒå›å½’æ¨¡å‹...")
model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
model.fit(X, y)
print("âœ… å›å½’æ¨¡å‹è®­ç»ƒå®Œæˆ")

# -----------------------------
# 5. å®šä¹‰æœç´¢ç©ºé—´ï¼ˆåŸºäºæ•°æ®çš„å®é™…èŒƒå›´ï¼‰
# -----------------------------
def get_search_space(X):
    space = []
    for col in X.columns:
        if col == 'a':
            # æ ¹æ®ä½ çš„ä¸šåŠ¡é€»è¾‘è®¾ç½® a çš„èŒƒå›´
            space.append(Real(0.05, 0.30, name=col))  # ç¤ºä¾‹ï¼ša âˆˆ [5%, 30%]
        elif col == 'b':
            # æ ¹æ®ä½ çš„ä¸šåŠ¡é€»è¾‘è®¾ç½® b çš„èŒƒå›´
            space.append(Real(0.05, 0.3, name=col))  # ç¤ºä¾‹ï¼šb âˆˆ [5%, 30%]
        elif col == 'é¦–è¡Œä¹°å…¥è§¦å‘ä»·':
            market_data = load_market_from_db()
            first_low =  market_data [0]['low_price']
            space.append(Real(first_low, first_low * 1.5, name=col))
        elif col == 'æ¨¡å‹è¡Œæ•°':
            space.append(Integer(5, 30, name=col))    # æ•´æ•°èŒƒå›´
        elif col == 'ä¹°å…¥é‡‘é¢':
            space.append(Real(1000, 50000, name=col))
        else:
            # å…œåº•ï¼šåŠ¨æ€è¾¹ç•Œï¼ˆä¸åº”è¯¥è§¦å‘ï¼‰
            low = max(0, X[col].min() * 0.9)
            high = X[col].max() * 1.1
            if col == 'æ¨¡å‹è¡Œæ•°':
                space.append(Integer(int(low), int(high), name=col))
            else:
                space.append(Real(low, high, name=col))
    return space

search_space = get_search_space(X)

# -----------------------------
# 6. ä¼˜åŒ–ç›®æ ‡å‡½æ•°
# -----------------------------
def objective(input_values):
    x_input = np.array(input_values).reshape(1, -1)
    pred = model.predict(x_input)[0]
    # skopt æœ€å°åŒ–ï¼Œæ‰€ä»¥æœ€å¤§åŒ–ç›®æ ‡éœ€å–è´Ÿ
    return -pred if OPTIMIZE_MODE == 'maximize' else pred

# -----------------------------
# 7. æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–
# -----------------------------
print("ğŸ” æ­£åœ¨æœç´¢å±€éƒ¨æœ€ä¼˜è¾“å…¥ç»„åˆï¼ˆçº¦éœ€ 30-60 ç§’ï¼‰...")
result = gp_minimize(
    func=objective,
    dimensions=search_space,
    n_calls=100,
    n_initial_points=20,
    random_state=42,
    verbose=False
)

# -----------------------------
# 8. è¾“å‡ºç»“æœ
# -----------------------------
optimal_inputs = result.x
optimal_value = -result.fun if OPTIMIZE_MODE == 'maximize' else result.fun

print("\n" + "="*70)
print(f"ğŸ† æœ€ä¼˜ç­–ç•¥å‚æ•° (ç›®æ ‡: {TARGET_COLUMN})")
print("="*70)
print("ã€æœ€ä¼˜è¾“å…¥ç»„åˆã€‘")
for col, val in zip(required_inputs, optimal_inputs):
    if col == 'æ¨¡å‹è¡Œæ•°':
        print(f"  {col:<12}: {int(round(val))}")
    else:
        print(f"  {col:<12}: {val:>10.4f}")

print(f"\nã€é¢„æµ‹çš„å±€éƒ¨æœ€ä¼˜è¾“å‡ºå€¼ã€‘: {optimal_value:.6f}")
print("="*70)


# # -----------------------------
# # 9. ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹å’Œç»“æœ
# # -----------------------------
# import joblib
# import json
# import os

# # åˆ›å»ºä¿å­˜ç›®å½•
# os.makedirs("saved_models", exist_ok=True)

# # ä¿å­˜éšæœºæ£®æ—æ¨¡å‹
# model_path = "saved_models/rf_model.pkl"
# joblib.dump(model, model_path)
# print(f"âœ… æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")

# # ä¿å­˜æœ€ä¼˜å‚æ•°
# required_inputs = ['a', 'b', 'é¦–è¡Œä¹°å…¥è§¦å‘ä»·', 'æ¨¡å‹è¡Œæ•°', 'ä¹°å…¥é‡‘é¢']
# best_params = {}
# for col, val in zip(required_inputs, optimal_inputs):
#     if col == 'æ¨¡å‹è¡Œæ•°':
#         best_params[col] = int(round(val))
#     else:
#         best_params[col] = float(val)
# best_params['æœ€ä¼˜ç›®æ ‡å€¼'] = float(optimal_value)
# best_params['ç›®æ ‡åˆ—'] = TARGET_COLUMN
# best_params['ä¼˜åŒ–æ–¹å‘'] = OPTIMIZE_MODE

# params_path = "saved_models/best_params.json"
# with open(params_path, 'w', encoding='utf-8') as f:
#     json.dump(best_params, f, ensure_ascii=False, indent=2)
# print(f"âœ… æœ€ä¼˜å‚æ•°å·²ä¿å­˜è‡³: {params_path}")

# # ä¿å­˜æœç´¢ç©ºé—´
# space_path = "saved_models/search_space.pkl"
# joblib.dump(search_space, space_path)
# print(f"âœ… æœç´¢ç©ºé—´å·²ä¿å­˜è‡³: {space_path}")